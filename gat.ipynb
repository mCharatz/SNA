{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook Content\n",
    "In this notebook the 3 datasets are being setup and tested using the GAT model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Import packages\n",
    "We will use _PyTorch_ as the main Neural Networks package, and we will add _PyTorch Geometric_ as a utility package that implements functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from gat import *\n",
    "import pandas as pd\n",
    "from utils import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Read input data\n",
    "Read the node features and edge list from the respective files.\n",
    "Construct a Data object from the features and edge list and split the data into train/val/test sets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Nodes: 16076, Val Nodes: 1102, Test Nodes: 1838\n",
      "\n",
      "Train Set Class Distribution: Left: 9336, Middle: 805, Right: 5935\n",
      "Val Set Class Distribution: Left: 836, Middle: 152, Right: 114\n",
      "Test Set Class Distribution: Left: 634, Middle: 570, Right: 634\n",
      "\n",
      "Nodes: 23607, Edges: 253528.0, Node Features: 17\n"
     ]
    }
   ],
   "source": [
    "node_features = pd.read_pickle('data/dataset3.pkl')\n",
    "edge_list = pd.read_pickle('data/graph_weighted_edgeList_61.pkl')\n",
    "data = graph_to_data_object(node_features, edge_list, 0.85, 0.05, 0.1)\n",
    "print(f\"\\nNodes: {data.x.shape[0]}, Edges: {int(data.edge_index.shape[1] / 2)}, Node Features: {data.num_features}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Grid search GAT Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {'architecture': 'two-layer', 'lr': 0.001, 'l2': 0.005, 'epochs': 500, 'dim_h1': 8, 'dim_h2': 0}, Run time: 15 seconds\n",
      "Config: {'architecture': 'two-layer', 'lr': 0.001, 'l2': 0.0005, 'epochs': 500, 'dim_h1': 8, 'dim_h2': 0}, Run time: 13 seconds\n",
      "Config: {'architecture': 'two-layer', 'lr': 0.0001, 'l2': 0.005, 'epochs': 500, 'dim_h1': 8, 'dim_h2': 0}, Run time: 13 seconds\n",
      "Config: {'architecture': 'two-layer', 'lr': 0.0001, 'l2': 0.0005, 'epochs': 500, 'dim_h1': 8, 'dim_h2': 0}, Run time: 14 seconds\n",
      "Config: {'architecture': 'three-layer', 'lr': 0.001, 'l2': 0.005, 'epochs': 500, 'dim_h1': 64, 'dim_h2': 8}, Run time: 25 seconds\n",
      "Config: {'architecture': 'three-layer', 'lr': 0.001, 'l2': 0.0005, 'epochs': 500, 'dim_h1': 64, 'dim_h2': 8}, Run time: 25 seconds\n",
      "Config: {'architecture': 'three-layer', 'lr': 0.0001, 'l2': 0.005, 'epochs': 500, 'dim_h1': 64, 'dim_h2': 8}, Run time: 26 seconds\n",
      "Config: {'architecture': 'three-layer', 'lr': 0.0001, 'l2': 0.0005, 'epochs': 500, 'dim_h1': 64, 'dim_h2': 8}, Run time: 25 seconds\n",
      "\n",
      "Run time: 155.71949863433838 seconds\n",
      "\n",
      "Best model config: {'architecture': 'two-layer', 'lr': 0.0001, 'l2': 0.0005, 'epochs': 500, 'dim_h1': 8, 'dim_h2': 0}\n",
      "\n",
      "GAT Dataset Test F1 score: 0.34494\n",
      "\n",
      "GAT Dataset Test AUC score: 0.48352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = [\n",
    "  {'architecture': ['two-layer'], 'lr': [1e-3, 1e-4], 'l2': [5e-3, 5e-4], 'epochs': [500], 'dim_h1': [8], 'dim_h2': [0]},\n",
    "  {'architecture': ['three-layer'], 'lr': [1e-3, 1e-4], 'l2': [5e-3, 5e-4], 'epochs': [500], 'dim_h1': [64], 'dim_h2': [8]},\n",
    "]\n",
    "\n",
    "best_model, best_config = grid_search_cv(data, 3, param_grid)\n",
    "print(f\"\\nRun time: {time.time() - start_time} seconds\")\n",
    "print(f\"\\nBest model config: {best_config}\")\n",
    "\n",
    "print(f'\\nGAT Dataset Test F1 score: {test_f1(best_model, data, data.test_mask):.5f}')\n",
    "print(f'\\nGAT Dataset Test AUC score: {test_auc(best_model, data, data.test_mask):.5f}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3. Train and test the best GAT Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.295 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch  10 | Train Loss: 1.291 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch  20 | Train Loss: 1.287 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch  30 | Train Loss: 1.283 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch  40 | Train Loss: 1.279 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch  50 | Train Loss: 1.275 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch  60 | Train Loss: 1.271 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch  70 | Train Loss: 1.267 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch  80 | Train Loss: 1.263 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch  90 | Train Loss: 1.259 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 100 | Train Loss: 1.255 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 110 | Train Loss: 1.251 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 120 | Train Loss: 1.247 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 130 | Train Loss: 1.244 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 140 | Train Loss: 1.240 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 150 | Train Loss: 1.236 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 160 | Train Loss: 1.233 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 170 | Train Loss: 1.229 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 180 | Train Loss: 1.226 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 190 | Train Loss: 1.222 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 200 | Train Loss: 1.219 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 210 | Train Loss: 1.215 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 220 | Train Loss: 1.212 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 230 | Train Loss: 1.209 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 240 | Train Loss: 1.206 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 250 | Train Loss: 1.202 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 260 | Train Loss: 1.199 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 270 | Train Loss: 1.196 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 280 | Train Loss: 1.193 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 290 | Train Loss: 1.190 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 300 | Train Loss: 1.187 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 310 | Train Loss: 1.184 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 320 | Train Loss: 1.182 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 330 | Train Loss: 1.179 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 340 | Train Loss: 1.176 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 350 | Train Loss: 1.173 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 360 | Train Loss: 1.171 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 370 | Train Loss: 1.168 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 380 | Train Loss: 1.165 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 390 | Train Loss: 1.163 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 400 | Train Loss: 1.160 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 410 | Train Loss: 1.158 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 420 | Train Loss: 1.155 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 430 | Train Loss: 1.153 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 440 | Train Loss: 1.151 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 450 | Train Loss: 1.149 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 460 | Train Loss: 1.147 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 470 | Train Loss: 1.145 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 480 | Train Loss: 1.143 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 490 | Train Loss: 1.141 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 500 | Train Loss: 1.140 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 510 | Train Loss: 1.138 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 520 | Train Loss: 1.137 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 530 | Train Loss: 1.135 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 540 | Train Loss: 1.134 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 550 | Train Loss: 1.133 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 560 | Train Loss: 1.132 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 570 | Train Loss: 1.131 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 580 | Train Loss: 1.130 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 590 | Train Loss: 1.129 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 600 | Train Loss: 1.128 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 610 | Train Loss: 1.126 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 620 | Train Loss: 1.125 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 630 | Train Loss: 1.124 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 640 | Train Loss: 1.123 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 650 | Train Loss: 1.122 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 660 | Train Loss: 1.121 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 670 | Train Loss: 1.120 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 680 | Train Loss: 1.119 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 690 | Train Loss: 1.118 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 700 | Train Loss: 1.117 | Train F1: 0.050074645434187603:.2f\n",
      "Epoch 710 | Train Loss: 1.116 | Train F1: 0.050945508833043045:.2f\n",
      "Epoch 720 | Train Loss: 1.114 | Train F1: 0.05262503110226424:.2f\n",
      "Epoch 730 | Train Loss: 1.113 | Train F1: 0.055610848469768596:.2f\n",
      "Epoch 740 | Train Loss: 1.112 | Train F1: 0.0632620054739985:.2f\n",
      "Epoch 750 | Train Loss: 1.110 | Train F1: 0.07221945757651158:.2f\n",
      "Epoch 760 | Train Loss: 1.108 | Train F1: 0.09679024632993281:.2f\n",
      "Epoch 770 | Train Loss: 1.106 | Train F1: 0.1550758895247574:.2f\n",
      "Epoch 780 | Train Loss: 1.104 | Train F1: 0.23090320975367007:.2f\n",
      "Epoch 790 | Train Loss: 1.101 | Train F1: 0.3377083851704404:.2f\n",
      "Epoch 800 | Train Loss: 1.097 | Train F1: 0.50572281662105:.2f\n",
      "Epoch 810 | Train Loss: 1.094 | Train F1: 0.575018661358547:.2f\n",
      "Epoch 820 | Train Loss: 1.090 | Train F1: 0.5762627519283404:.2f\n",
      "Epoch 830 | Train Loss: 1.086 | Train F1: 0.5763871609853197:.2f\n",
      "Epoch 840 | Train Loss: 1.082 | Train F1: 0.575391888529485:.2f\n",
      "Epoch 850 | Train Loss: 1.079 | Train F1: 0.5747698432445882:.2f\n",
      "Epoch 860 | Train Loss: 1.075 | Train F1: 0.5749564568300572:.2f\n",
      "Epoch 870 | Train Loss: 1.072 | Train F1: 0.5746454341876088:.2f\n",
      "Epoch 880 | Train Loss: 1.069 | Train F1: 0.5758273202289127:.2f\n",
      "Epoch 890 | Train Loss: 1.066 | Train F1: 0.5758895247574023:.2f\n",
      "Epoch 900 | Train Loss: 1.063 | Train F1: 0.5764493655138094:.2f\n",
      "Epoch 910 | Train Loss: 1.060 | Train F1: 0.5764493655138094:.2f\n",
      "Epoch 920 | Train Loss: 1.058 | Train F1: 0.5768847972132372:.2f\n",
      "Epoch 930 | Train Loss: 1.055 | Train F1: 0.5767603881562577:.2f\n",
      "Epoch 940 | Train Loss: 1.053 | Train F1: 0.5771958198556855:.2f\n",
      "Epoch 950 | Train Loss: 1.050 | Train F1: 0.5774446379696442:.2f\n",
      "Epoch 960 | Train Loss: 1.048 | Train F1: 0.5773202289126649:.2f\n",
      "Epoch 970 | Train Loss: 1.045 | Train F1: 0.5770714107987062:.2f\n",
      "Epoch 980 | Train Loss: 1.043 | Train F1: 0.5771958198556855:.2f\n",
      "Epoch 990 | Train Loss: 1.041 | Train F1: 0.5773202289126649:.2f\n",
      "Epoch 1000 | Train Loss: 1.039 | Train F1: 0.5773824334411545:.2f\n",
      "Epoch 1010 | Train Loss: 1.037 | Train F1: 0.5774446379696442:.2f\n",
      "Epoch 1020 | Train Loss: 1.034 | Train F1: 0.5775068424981339:.2f\n",
      "Epoch 1030 | Train Loss: 1.032 | Train F1: 0.5775690470266235:.2f\n",
      "Epoch 1040 | Train Loss: 1.030 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 1050 | Train Loss: 1.029 | Train F1: 0.5780044787260512:.2f\n",
      "Epoch 1060 | Train Loss: 1.027 | Train F1: 0.5794973874098034:.2f\n",
      "Epoch 1070 | Train Loss: 1.025 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 1080 | Train Loss: 1.023 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 1090 | Train Loss: 1.022 | Train F1: 0.5798706145807415:.2f\n",
      "Epoch 1100 | Train Loss: 1.020 | Train F1: 0.5799950236377208:.2f\n",
      "Epoch 1110 | Train Loss: 1.018 | Train F1: 0.5802438417516795:.2f\n",
      "Epoch 1120 | Train Loss: 1.017 | Train F1: 0.5804926598656382:.2f\n",
      "Epoch 1130 | Train Loss: 1.015 | Train F1: 0.5809902960935556:.2f\n",
      "Epoch 1140 | Train Loss: 1.014 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1150 | Train Loss: 1.012 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1160 | Train Loss: 1.011 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1170 | Train Loss: 1.010 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1180 | Train Loss: 1.008 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1190 | Train Loss: 1.007 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1200 | Train Loss: 1.006 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1210 | Train Loss: 1.005 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1220 | Train Loss: 1.003 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1230 | Train Loss: 1.002 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1240 | Train Loss: 1.001 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1250 | Train Loss: 1.000 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1260 | Train Loss: 0.999 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1270 | Train Loss: 0.998 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1280 | Train Loss: 0.997 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1290 | Train Loss: 0.996 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1300 | Train Loss: 0.995 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1310 | Train Loss: 0.994 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1320 | Train Loss: 0.993 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1330 | Train Loss: 0.993 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1340 | Train Loss: 0.992 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1350 | Train Loss: 0.991 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1360 | Train Loss: 0.990 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1370 | Train Loss: 0.989 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1380 | Train Loss: 0.989 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1390 | Train Loss: 0.988 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1400 | Train Loss: 0.987 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1410 | Train Loss: 0.987 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1420 | Train Loss: 0.986 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1430 | Train Loss: 0.985 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1440 | Train Loss: 0.985 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1450 | Train Loss: 0.984 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1460 | Train Loss: 0.983 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1470 | Train Loss: 0.983 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1480 | Train Loss: 0.982 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1490 | Train Loss: 0.982 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1500 | Train Loss: 0.981 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1510 | Train Loss: 0.981 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1520 | Train Loss: 0.980 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1530 | Train Loss: 0.980 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1540 | Train Loss: 0.979 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1550 | Train Loss: 0.979 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1560 | Train Loss: 0.978 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1570 | Train Loss: 0.978 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1580 | Train Loss: 0.977 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1590 | Train Loss: 0.977 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1600 | Train Loss: 0.977 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1610 | Train Loss: 0.976 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1620 | Train Loss: 0.976 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1630 | Train Loss: 0.975 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1640 | Train Loss: 0.975 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1650 | Train Loss: 0.975 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1660 | Train Loss: 0.974 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1670 | Train Loss: 0.974 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1680 | Train Loss: 0.973 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1690 | Train Loss: 0.973 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1700 | Train Loss: 0.973 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1710 | Train Loss: 0.972 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1720 | Train Loss: 0.972 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1730 | Train Loss: 0.972 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1740 | Train Loss: 0.971 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1750 | Train Loss: 0.971 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1760 | Train Loss: 0.971 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1770 | Train Loss: 0.971 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1780 | Train Loss: 0.970 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1790 | Train Loss: 0.970 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1800 | Train Loss: 0.970 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1810 | Train Loss: 0.969 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1820 | Train Loss: 0.969 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1830 | Train Loss: 0.969 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1840 | Train Loss: 0.969 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1850 | Train Loss: 0.968 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1860 | Train Loss: 0.968 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1870 | Train Loss: 0.968 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1880 | Train Loss: 0.967 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1890 | Train Loss: 0.967 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1900 | Train Loss: 0.967 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1910 | Train Loss: 0.967 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1920 | Train Loss: 0.966 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1930 | Train Loss: 0.966 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1940 | Train Loss: 0.966 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1950 | Train Loss: 0.966 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1960 | Train Loss: 0.965 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1970 | Train Loss: 0.965 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1980 | Train Loss: 0.965 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 1990 | Train Loss: 0.965 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2000 | Train Loss: 0.964 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2010 | Train Loss: 0.964 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2020 | Train Loss: 0.964 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2030 | Train Loss: 0.964 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2040 | Train Loss: 0.963 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2050 | Train Loss: 0.963 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2060 | Train Loss: 0.963 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2070 | Train Loss: 0.962 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2080 | Train Loss: 0.962 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2090 | Train Loss: 0.962 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2100 | Train Loss: 0.961 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2110 | Train Loss: 0.961 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2120 | Train Loss: 0.961 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2130 | Train Loss: 0.961 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2140 | Train Loss: 0.960 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2150 | Train Loss: 0.960 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2160 | Train Loss: 0.960 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2170 | Train Loss: 0.959 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2180 | Train Loss: 0.959 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2190 | Train Loss: 0.959 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2200 | Train Loss: 0.959 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2210 | Train Loss: 0.958 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2220 | Train Loss: 0.958 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2230 | Train Loss: 0.958 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2240 | Train Loss: 0.958 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2250 | Train Loss: 0.957 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2260 | Train Loss: 0.957 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2270 | Train Loss: 0.957 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2280 | Train Loss: 0.957 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2290 | Train Loss: 0.957 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 2300 | Train Loss: 0.957 | Train F1: 0.5808036825080866:.2f\n",
      "Epoch 2310 | Train Loss: 0.956 | Train F1: 0.5806170689226176:.2f\n",
      "Epoch 2320 | Train Loss: 0.956 | Train F1: 0.5806170689226176:.2f\n",
      "Epoch 2330 | Train Loss: 0.956 | Train F1: 0.5804926598656382:.2f\n",
      "Epoch 2340 | Train Loss: 0.956 | Train F1: 0.5804926598656382:.2f\n",
      "Epoch 2350 | Train Loss: 0.956 | Train F1: 0.5806170689226176:.2f\n",
      "Epoch 2360 | Train Loss: 0.956 | Train F1: 0.5806170689226176:.2f\n",
      "Epoch 2370 | Train Loss: 0.955 | Train F1: 0.5806170689226176:.2f\n",
      "Epoch 2380 | Train Loss: 0.955 | Train F1: 0.5806170689226176:.2f\n",
      "Epoch 2390 | Train Loss: 0.955 | Train F1: 0.5806792734511073:.2f\n",
      "Epoch 2400 | Train Loss: 0.955 | Train F1: 0.5806792734511073:.2f\n",
      "Epoch 2410 | Train Loss: 0.955 | Train F1: 0.5806792734511073:.2f\n",
      "Epoch 2420 | Train Loss: 0.955 | Train F1: 0.5806170689226176:.2f\n",
      "Epoch 2430 | Train Loss: 0.955 | Train F1: 0.5806170689226176:.2f\n",
      "Epoch 2440 | Train Loss: 0.955 | Train F1: 0.5806170689226176:.2f\n",
      "Epoch 2450 | Train Loss: 0.954 | Train F1: 0.5806170689226176:.2f\n",
      "Epoch 2460 | Train Loss: 0.954 | Train F1: 0.5808658870365763:.2f\n",
      "Epoch 2470 | Train Loss: 0.954 | Train F1: 0.5808658870365763:.2f\n",
      "Epoch 2480 | Train Loss: 0.954 | Train F1: 0.5809902960935556:.2f\n",
      "Epoch 2490 | Train Loss: 0.954 | Train F1: 0.5803060462801692:.2f\n",
      "Epoch 2500 | Train Loss: 0.954 | Train F1: 0.5802438417516795:.2f\n",
      "Epoch 2510 | Train Loss: 0.954 | Train F1: 0.5802438417516795:.2f\n",
      "Epoch 2520 | Train Loss: 0.954 | Train F1: 0.5794351828813138:.2f\n",
      "Epoch 2530 | Train Loss: 0.954 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 2540 | Train Loss: 0.954 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 2550 | Train Loss: 0.953 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 2560 | Train Loss: 0.953 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 2570 | Train Loss: 0.953 | Train F1: 0.5786887285394376:.2f\n",
      "Epoch 2580 | Train Loss: 0.953 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 2590 | Train Loss: 0.953 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 2600 | Train Loss: 0.953 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 2610 | Train Loss: 0.953 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 2620 | Train Loss: 0.953 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 2630 | Train Loss: 0.953 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 2640 | Train Loss: 0.953 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 2650 | Train Loss: 0.953 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 2660 | Train Loss: 0.953 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 2670 | Train Loss: 0.952 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 2680 | Train Loss: 0.952 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 2690 | Train Loss: 0.952 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 2700 | Train Loss: 0.952 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 2710 | Train Loss: 0.952 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 2720 | Train Loss: 0.952 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 2730 | Train Loss: 0.952 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 2740 | Train Loss: 0.952 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 2750 | Train Loss: 0.952 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 2760 | Train Loss: 0.952 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 2770 | Train Loss: 0.952 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 2780 | Train Loss: 0.952 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 2790 | Train Loss: 0.952 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 2800 | Train Loss: 0.952 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 2810 | Train Loss: 0.951 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 2820 | Train Loss: 0.951 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 2830 | Train Loss: 0.951 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 2840 | Train Loss: 0.951 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 2850 | Train Loss: 0.951 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 2860 | Train Loss: 0.951 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 2870 | Train Loss: 0.951 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 2880 | Train Loss: 0.951 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 2890 | Train Loss: 0.951 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 2900 | Train Loss: 0.951 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 2910 | Train Loss: 0.951 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 2920 | Train Loss: 0.951 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 2930 | Train Loss: 0.951 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 2940 | Train Loss: 0.951 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 2950 | Train Loss: 0.950 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 2960 | Train Loss: 0.950 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 2970 | Train Loss: 0.950 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 2980 | Train Loss: 0.950 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 2990 | Train Loss: 0.950 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 3000 | Train Loss: 0.950 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 3010 | Train Loss: 0.950 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 3020 | Train Loss: 0.950 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 3030 | Train Loss: 0.950 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 3040 | Train Loss: 0.950 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 3050 | Train Loss: 0.950 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 3060 | Train Loss: 0.950 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 3070 | Train Loss: 0.950 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 3080 | Train Loss: 0.950 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 3090 | Train Loss: 0.950 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 3100 | Train Loss: 0.950 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 3110 | Train Loss: 0.950 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 3120 | Train Loss: 0.950 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 3130 | Train Loss: 0.950 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 3140 | Train Loss: 0.950 | Train F1: 0.5780044787260512:.2f\n",
      "Epoch 3150 | Train Loss: 0.949 | Train F1: 0.5780044787260512:.2f\n",
      "Epoch 3160 | Train Loss: 0.949 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 3170 | Train Loss: 0.949 | Train F1: 0.5781910923115203:.2f\n",
      "Epoch 3180 | Train Loss: 0.949 | Train F1: 0.5782532968400099:.2f\n",
      "Epoch 3190 | Train Loss: 0.949 | Train F1: 0.5781910923115203:.2f\n",
      "Epoch 3200 | Train Loss: 0.949 | Train F1: 0.5780666832545409:.2f\n",
      "Epoch 3210 | Train Loss: 0.949 | Train F1: 0.5780666832545409:.2f\n",
      "Epoch 3220 | Train Loss: 0.949 | Train F1: 0.5781288877830306:.2f\n",
      "Epoch 3230 | Train Loss: 0.949 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 3240 | Train Loss: 0.949 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 3250 | Train Loss: 0.949 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 3260 | Train Loss: 0.949 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 3270 | Train Loss: 0.949 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 3280 | Train Loss: 0.949 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 3290 | Train Loss: 0.949 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 3300 | Train Loss: 0.949 | Train F1: 0.5786887285394376:.2f\n",
      "Epoch 3310 | Train Loss: 0.949 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 3320 | Train Loss: 0.949 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 3330 | Train Loss: 0.949 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 3340 | Train Loss: 0.949 | Train F1: 0.5782532968400099:.2f\n",
      "Epoch 3350 | Train Loss: 0.949 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 3360 | Train Loss: 0.949 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 3370 | Train Loss: 0.949 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 3380 | Train Loss: 0.949 | Train F1: 0.5794351828813138:.2f\n",
      "Epoch 3390 | Train Loss: 0.949 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 3400 | Train Loss: 0.949 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 3410 | Train Loss: 0.949 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 3420 | Train Loss: 0.948 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 3430 | Train Loss: 0.948 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 3440 | Train Loss: 0.948 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 3450 | Train Loss: 0.948 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 3460 | Train Loss: 0.948 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 3470 | Train Loss: 0.948 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 3480 | Train Loss: 0.948 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 3490 | Train Loss: 0.948 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 3500 | Train Loss: 0.948 | Train F1: 0.5781288877830306:.2f\n",
      "Epoch 3510 | Train Loss: 0.948 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 3520 | Train Loss: 0.948 | Train F1: 0.5779422741975616:.2f\n",
      "Epoch 3530 | Train Loss: 0.948 | Train F1: 0.5780044787260512:.2f\n",
      "Epoch 3540 | Train Loss: 0.948 | Train F1: 0.5781288877830306:.2f\n",
      "Epoch 3550 | Train Loss: 0.948 | Train F1: 0.5780044787260512:.2f\n",
      "Epoch 3560 | Train Loss: 0.948 | Train F1: 0.5779422741975616:.2f\n",
      "Epoch 3570 | Train Loss: 0.948 | Train F1: 0.5778800696690719:.2f\n",
      "Epoch 3580 | Train Loss: 0.948 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 3590 | Train Loss: 0.948 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 3600 | Train Loss: 0.948 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3610 | Train Loss: 0.948 | Train F1: 0.5777556606120926:.2f\n",
      "Epoch 3620 | Train Loss: 0.948 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 3630 | Train Loss: 0.948 | Train F1: 0.5778800696690719:.2f\n",
      "Epoch 3640 | Train Loss: 0.948 | Train F1: 0.5780044787260512:.2f\n",
      "Epoch 3650 | Train Loss: 0.948 | Train F1: 0.5780044787260512:.2f\n",
      "Epoch 3660 | Train Loss: 0.948 | Train F1: 0.5780044787260512:.2f\n",
      "Epoch 3670 | Train Loss: 0.948 | Train F1: 0.5778800696690719:.2f\n",
      "Epoch 3680 | Train Loss: 0.948 | Train F1: 0.5777556606120926:.2f\n",
      "Epoch 3690 | Train Loss: 0.948 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3700 | Train Loss: 0.948 | Train F1: 0.5775068424981339:.2f\n",
      "Epoch 3710 | Train Loss: 0.948 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3720 | Train Loss: 0.948 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3730 | Train Loss: 0.948 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3740 | Train Loss: 0.948 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3750 | Train Loss: 0.948 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 3760 | Train Loss: 0.948 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3770 | Train Loss: 0.948 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 3780 | Train Loss: 0.948 | Train F1: 0.5775068424981339:.2f\n",
      "Epoch 3790 | Train Loss: 0.948 | Train F1: 0.5775690470266235:.2f\n",
      "Epoch 3800 | Train Loss: 0.948 | Train F1: 0.5775690470266235:.2f\n",
      "Epoch 3810 | Train Loss: 0.948 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3820 | Train Loss: 0.948 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3830 | Train Loss: 0.948 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3840 | Train Loss: 0.948 | Train F1: 0.5774446379696442:.2f\n",
      "Epoch 3850 | Train Loss: 0.948 | Train F1: 0.5775068424981339:.2f\n",
      "Epoch 3860 | Train Loss: 0.947 | Train F1: 0.5777556606120926:.2f\n",
      "Epoch 3870 | Train Loss: 0.947 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 3880 | Train Loss: 0.947 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 3890 | Train Loss: 0.947 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 3900 | Train Loss: 0.947 | Train F1: 0.5778800696690719:.2f\n",
      "Epoch 3910 | Train Loss: 0.947 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 3920 | Train Loss: 0.947 | Train F1: 0.5777556606120926:.2f\n",
      "Epoch 3930 | Train Loss: 0.947 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3940 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 3950 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 3960 | Train Loss: 0.947 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3970 | Train Loss: 0.947 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3980 | Train Loss: 0.947 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 3990 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4000 | Train Loss: 0.947 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 4010 | Train Loss: 0.947 | Train F1: 0.5777556606120926:.2f\n",
      "Epoch 4020 | Train Loss: 0.947 | Train F1: 0.5777556606120926:.2f\n",
      "Epoch 4030 | Train Loss: 0.947 | Train F1: 0.5777556606120926:.2f\n",
      "Epoch 4040 | Train Loss: 0.947 | Train F1: 0.5777556606120926:.2f\n",
      "Epoch 4050 | Train Loss: 0.947 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 4060 | Train Loss: 0.947 | Train F1: 0.5778800696690719:.2f\n",
      "Epoch 4070 | Train Loss: 0.947 | Train F1: 0.5777556606120926:.2f\n",
      "Epoch 4080 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4090 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4100 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4110 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4120 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4130 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4140 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4150 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4160 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4170 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4180 | Train Loss: 0.947 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 4190 | Train Loss: 0.947 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 4200 | Train Loss: 0.947 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 4210 | Train Loss: 0.947 | Train F1: 0.5775068424981339:.2f\n",
      "Epoch 4220 | Train Loss: 0.947 | Train F1: 0.5774446379696442:.2f\n",
      "Epoch 4230 | Train Loss: 0.947 | Train F1: 0.5775690470266235:.2f\n",
      "Epoch 4240 | Train Loss: 0.947 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 4250 | Train Loss: 0.947 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 4260 | Train Loss: 0.947 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 4270 | Train Loss: 0.947 | Train F1: 0.5776312515551132:.2f\n",
      "Epoch 4280 | Train Loss: 0.947 | Train F1: 0.5776934560836029:.2f\n",
      "Epoch 4290 | Train Loss: 0.947 | Train F1: 0.5775690470266235:.2f\n",
      "Epoch 4300 | Train Loss: 0.947 | Train F1: 0.5773824334411545:.2f\n",
      "Epoch 4310 | Train Loss: 0.947 | Train F1: 0.5773824334411545:.2f\n",
      "Epoch 4320 | Train Loss: 0.947 | Train F1: 0.5773202289126649:.2f\n",
      "Epoch 4330 | Train Loss: 0.947 | Train F1: 0.5773202289126649:.2f\n",
      "Epoch 4340 | Train Loss: 0.947 | Train F1: 0.5771958198556855:.2f\n",
      "Epoch 4350 | Train Loss: 0.947 | Train F1: 0.5773824334411545:.2f\n",
      "Epoch 4360 | Train Loss: 0.947 | Train F1: 0.5773202289126649:.2f\n",
      "Epoch 4370 | Train Loss: 0.947 | Train F1: 0.5773824334411545:.2f\n",
      "Epoch 4380 | Train Loss: 0.947 | Train F1: 0.5772580243841752:.2f\n",
      "Epoch 4390 | Train Loss: 0.947 | Train F1: 0.5774446379696442:.2f\n",
      "Epoch 4400 | Train Loss: 0.947 | Train F1: 0.5774446379696442:.2f\n",
      "Epoch 4410 | Train Loss: 0.947 | Train F1: 0.5771336153271959:.2f\n",
      "Epoch 4420 | Train Loss: 0.947 | Train F1: 0.5772580243841752:.2f\n",
      "Epoch 4430 | Train Loss: 0.947 | Train F1: 0.5771336153271959:.2f\n",
      "Epoch 4440 | Train Loss: 0.947 | Train F1: 0.5770092062702165:.2f\n",
      "Epoch 4450 | Train Loss: 0.947 | Train F1: 0.5770092062702165:.2f\n",
      "Epoch 4460 | Train Loss: 0.947 | Train F1: 0.5770092062702165:.2f\n",
      "Epoch 4470 | Train Loss: 0.947 | Train F1: 0.5769470017417268:.2f\n",
      "Epoch 4480 | Train Loss: 0.947 | Train F1: 0.5769470017417268:.2f\n",
      "Epoch 4490 | Train Loss: 0.947 | Train F1: 0.5768847972132372:.2f\n",
      "Epoch 4500 | Train Loss: 0.947 | Train F1: 0.5768847972132372:.2f\n",
      "Epoch 4510 | Train Loss: 0.947 | Train F1: 0.5769470017417268:.2f\n",
      "Epoch 4520 | Train Loss: 0.947 | Train F1: 0.5768847972132372:.2f\n",
      "Epoch 4530 | Train Loss: 0.947 | Train F1: 0.5768225926847474:.2f\n",
      "Epoch 4540 | Train Loss: 0.947 | Train F1: 0.5768847972132372:.2f\n",
      "Epoch 4550 | Train Loss: 0.947 | Train F1: 0.5768225926847474:.2f\n",
      "Epoch 4560 | Train Loss: 0.946 | Train F1: 0.5767603881562577:.2f\n",
      "Epoch 4570 | Train Loss: 0.946 | Train F1: 0.5771336153271959:.2f\n",
      "Epoch 4580 | Train Loss: 0.946 | Train F1: 0.5771336153271959:.2f\n",
      "Epoch 4590 | Train Loss: 0.946 | Train F1: 0.5771336153271959:.2f\n",
      "Epoch 4600 | Train Loss: 0.946 | Train F1: 0.5770714107987062:.2f\n",
      "Epoch 4610 | Train Loss: 0.946 | Train F1: 0.5770714107987062:.2f\n",
      "Epoch 4620 | Train Loss: 0.946 | Train F1: 0.5768225926847474:.2f\n",
      "Epoch 4630 | Train Loss: 0.946 | Train F1: 0.5767603881562577:.2f\n",
      "Epoch 4640 | Train Loss: 0.946 | Train F1: 0.57632495645683:.2f\n",
      "Epoch 4650 | Train Loss: 0.946 | Train F1: 0.576138342871361:.2f\n",
      "Epoch 4660 | Train Loss: 0.946 | Train F1: 0.576138342871361:.2f\n",
      "Epoch 4670 | Train Loss: 0.946 | Train F1: 0.5762005473998507:.2f\n",
      "Epoch 4680 | Train Loss: 0.946 | Train F1: 0.57632495645683:.2f\n",
      "Epoch 4690 | Train Loss: 0.946 | Train F1: 0.576138342871361:.2f\n",
      "Epoch 4700 | Train Loss: 0.946 | Train F1: 0.5762005473998507:.2f\n",
      "Epoch 4710 | Train Loss: 0.946 | Train F1: 0.576138342871361:.2f\n",
      "Epoch 4720 | Train Loss: 0.946 | Train F1: 0.5762627519283404:.2f\n",
      "Epoch 4730 | Train Loss: 0.946 | Train F1: 0.57632495645683:.2f\n",
      "Epoch 4740 | Train Loss: 0.946 | Train F1: 0.5762627519283404:.2f\n",
      "Epoch 4750 | Train Loss: 0.946 | Train F1: 0.5762627519283404:.2f\n",
      "Epoch 4760 | Train Loss: 0.946 | Train F1: 0.5762627519283404:.2f\n",
      "Epoch 4770 | Train Loss: 0.946 | Train F1: 0.57632495645683:.2f\n",
      "Epoch 4780 | Train Loss: 0.946 | Train F1: 0.5758895247574023:.2f\n",
      "Epoch 4790 | Train Loss: 0.946 | Train F1: 0.5758273202289127:.2f\n",
      "Epoch 4800 | Train Loss: 0.946 | Train F1: 0.5758273202289127:.2f\n",
      "Epoch 4810 | Train Loss: 0.946 | Train F1: 0.576138342871361:.2f\n",
      "Epoch 4820 | Train Loss: 0.946 | Train F1: 0.5762627519283404:.2f\n",
      "Epoch 4830 | Train Loss: 0.946 | Train F1: 0.57632495645683:.2f\n",
      "Epoch 4840 | Train Loss: 0.946 | Train F1: 0.57632495645683:.2f\n",
      "Epoch 4850 | Train Loss: 0.946 | Train F1: 0.5764493655138094:.2f\n",
      "Epoch 4860 | Train Loss: 0.946 | Train F1: 0.576511570042299:.2f\n",
      "Epoch 4870 | Train Loss: 0.946 | Train F1: 0.5763871609853197:.2f\n",
      "Epoch 4880 | Train Loss: 0.946 | Train F1: 0.5763871609853197:.2f\n",
      "Epoch 4890 | Train Loss: 0.946 | Train F1: 0.576511570042299:.2f\n",
      "Epoch 4900 | Train Loss: 0.946 | Train F1: 0.576511570042299:.2f\n",
      "Epoch 4910 | Train Loss: 0.946 | Train F1: 0.576511570042299:.2f\n",
      "Epoch 4920 | Train Loss: 0.946 | Train F1: 0.5768225926847474:.2f\n",
      "Epoch 4930 | Train Loss: 0.946 | Train F1: 0.5768225926847474:.2f\n",
      "Epoch 4940 | Train Loss: 0.946 | Train F1: 0.5768225926847474:.2f\n",
      "Epoch 4950 | Train Loss: 0.946 | Train F1: 0.5768225926847474:.2f\n",
      "Epoch 4960 | Train Loss: 0.946 | Train F1: 0.5768225926847474:.2f\n",
      "Epoch 4970 | Train Loss: 0.946 | Train F1: 0.5768225926847474:.2f\n",
      "Epoch 4980 | Train Loss: 0.946 | Train F1: 0.5768225926847474:.2f\n",
      "Epoch 4990 | Train Loss: 0.946 | Train F1: 0.5768847972132372:.2f\n",
      "Epoch 5000 | Train Loss: 0.946 | Train F1: 0.5768847972132372:.2f\n",
      "Epoch 5010 | Train Loss: 0.946 | Train F1: 0.5770092062702165:.2f\n",
      "Epoch 5020 | Train Loss: 0.946 | Train F1: 0.5770092062702165:.2f\n",
      "Epoch 5030 | Train Loss: 0.946 | Train F1: 0.5770092062702165:.2f\n",
      "Epoch 5040 | Train Loss: 0.946 | Train F1: 0.5770714107987062:.2f\n",
      "Epoch 5050 | Train Loss: 0.946 | Train F1: 0.5770714107987062:.2f\n",
      "Epoch 5060 | Train Loss: 0.946 | Train F1: 0.5773202289126649:.2f\n",
      "Epoch 5070 | Train Loss: 0.946 | Train F1: 0.5772580243841752:.2f\n",
      "Epoch 5080 | Train Loss: 0.946 | Train F1: 0.5774446379696442:.2f\n",
      "Epoch 5090 | Train Loss: 0.946 | Train F1: 0.5775690470266235:.2f\n",
      "Epoch 5100 | Train Loss: 0.946 | Train F1: 0.5778178651405822:.2f\n",
      "Epoch 5110 | Train Loss: 0.946 | Train F1: 0.5777556606120926:.2f\n",
      "Epoch 5120 | Train Loss: 0.946 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 5130 | Train Loss: 0.946 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 5140 | Train Loss: 0.946 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 5150 | Train Loss: 0.946 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 5160 | Train Loss: 0.946 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 5170 | Train Loss: 0.946 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 5180 | Train Loss: 0.946 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5190 | Train Loss: 0.946 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 5200 | Train Loss: 0.946 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5210 | Train Loss: 0.946 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 5220 | Train Loss: 0.946 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 5230 | Train Loss: 0.946 | Train F1: 0.5782532968400099:.2f\n",
      "Epoch 5240 | Train Loss: 0.946 | Train F1: 0.5781910923115203:.2f\n",
      "Epoch 5250 | Train Loss: 0.946 | Train F1: 0.5781910923115203:.2f\n",
      "Epoch 5260 | Train Loss: 0.946 | Train F1: 0.5779422741975616:.2f\n",
      "Epoch 5270 | Train Loss: 0.946 | Train F1: 0.5780666832545409:.2f\n",
      "Epoch 5280 | Train Loss: 0.946 | Train F1: 0.5782532968400099:.2f\n",
      "Epoch 5290 | Train Loss: 0.946 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5300 | Train Loss: 0.945 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 5310 | Train Loss: 0.945 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 5320 | Train Loss: 0.945 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5330 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5340 | Train Loss: 0.945 | Train F1: 0.5782532968400099:.2f\n",
      "Epoch 5350 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5360 | Train Loss: 0.945 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 5370 | Train Loss: 0.945 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 5380 | Train Loss: 0.945 | Train F1: 0.5781910923115203:.2f\n",
      "Epoch 5390 | Train Loss: 0.945 | Train F1: 0.5781910923115203:.2f\n",
      "Epoch 5400 | Train Loss: 0.945 | Train F1: 0.5782532968400099:.2f\n",
      "Epoch 5410 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5420 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5430 | Train Loss: 0.945 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 5440 | Train Loss: 0.945 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 5450 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5460 | Train Loss: 0.945 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 5470 | Train Loss: 0.945 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 5480 | Train Loss: 0.945 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 5490 | Train Loss: 0.945 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 5500 | Train Loss: 0.945 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 5510 | Train Loss: 0.945 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5520 | Train Loss: 0.945 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5530 | Train Loss: 0.945 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5540 | Train Loss: 0.945 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5550 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5560 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5570 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5580 | Train Loss: 0.945 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 5590 | Train Loss: 0.945 | Train F1: 0.5782532968400099:.2f\n",
      "Epoch 5600 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5610 | Train Loss: 0.945 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 5620 | Train Loss: 0.945 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5630 | Train Loss: 0.945 | Train F1: 0.5786887285394376:.2f\n",
      "Epoch 5640 | Train Loss: 0.945 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 5650 | Train Loss: 0.945 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 5660 | Train Loss: 0.945 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 5670 | Train Loss: 0.945 | Train F1: 0.5786887285394376:.2f\n",
      "Epoch 5680 | Train Loss: 0.945 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5690 | Train Loss: 0.945 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 5700 | Train Loss: 0.945 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 5710 | Train Loss: 0.945 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 5720 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5730 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5740 | Train Loss: 0.945 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 5750 | Train Loss: 0.945 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5760 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5770 | Train Loss: 0.945 | Train F1: 0.5782532968400099:.2f\n",
      "Epoch 5780 | Train Loss: 0.945 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 5790 | Train Loss: 0.945 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 5800 | Train Loss: 0.945 | Train F1: 0.5783155013684996:.2f\n",
      "Epoch 5810 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5820 | Train Loss: 0.945 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 5830 | Train Loss: 0.945 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5840 | Train Loss: 0.945 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 5850 | Train Loss: 0.945 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5860 | Train Loss: 0.945 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 5870 | Train Loss: 0.945 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 5880 | Train Loss: 0.945 | Train F1: 0.5786887285394376:.2f\n",
      "Epoch 5890 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 5900 | Train Loss: 0.945 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 5910 | Train Loss: 0.945 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 5920 | Train Loss: 0.945 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 5930 | Train Loss: 0.945 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 5940 | Train Loss: 0.945 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 5950 | Train Loss: 0.945 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 5960 | Train Loss: 0.945 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 5970 | Train Loss: 0.945 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 5980 | Train Loss: 0.945 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 5990 | Train Loss: 0.945 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 6000 | Train Loss: 0.945 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 6010 | Train Loss: 0.945 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 6020 | Train Loss: 0.945 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 6030 | Train Loss: 0.945 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 6040 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6050 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6060 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6070 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6080 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6090 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6100 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6110 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6120 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6130 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6140 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6150 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6160 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6170 | Train Loss: 0.945 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 6180 | Train Loss: 0.945 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 6190 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6200 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6210 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6220 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6230 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6240 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6250 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6260 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6270 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6280 | Train Loss: 0.945 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 6290 | Train Loss: 0.945 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 6300 | Train Loss: 0.945 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 6310 | Train Loss: 0.945 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 6320 | Train Loss: 0.945 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 6330 | Train Loss: 0.945 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 6340 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6350 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6360 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6370 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6380 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6390 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6400 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6410 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6420 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6430 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6440 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6450 | Train Loss: 0.945 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 6460 | Train Loss: 0.945 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 6470 | Train Loss: 0.945 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 6480 | Train Loss: 0.945 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 6490 | Train Loss: 0.945 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 6500 | Train Loss: 0.945 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 6510 | Train Loss: 0.945 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 6520 | Train Loss: 0.945 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 6530 | Train Loss: 0.945 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 6540 | Train Loss: 0.945 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 6550 | Train Loss: 0.945 | Train F1: 0.5786887285394376:.2f\n",
      "Epoch 6560 | Train Loss: 0.945 | Train F1: 0.5786887285394376:.2f\n",
      "Epoch 6570 | Train Loss: 0.945 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 6580 | Train Loss: 0.945 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 6590 | Train Loss: 0.945 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 6600 | Train Loss: 0.945 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 6610 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6620 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6630 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6640 | Train Loss: 0.945 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 6650 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6660 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6670 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6680 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6690 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6700 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6710 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6720 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6730 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6740 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6750 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6760 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6770 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6780 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6790 | Train Loss: 0.945 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 6800 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6810 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6820 | Train Loss: 0.945 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 6830 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6840 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6850 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6860 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6870 | Train Loss: 0.945 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 6880 | Train Loss: 0.945 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 6890 | Train Loss: 0.945 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 6900 | Train Loss: 0.945 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 6910 | Train Loss: 0.945 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 6920 | Train Loss: 0.945 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 6930 | Train Loss: 0.945 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 6940 | Train Loss: 0.945 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 6950 | Train Loss: 0.945 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 6960 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 6970 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 6980 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 6990 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7000 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7010 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7020 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7030 | Train Loss: 0.944 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 7040 | Train Loss: 0.944 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 7050 | Train Loss: 0.944 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 7060 | Train Loss: 0.944 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 7070 | Train Loss: 0.944 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 7080 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7090 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7100 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7110 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7120 | Train Loss: 0.944 | Train F1: 0.5793729783528241:.2f\n",
      "Epoch 7130 | Train Loss: 0.944 | Train F1: 0.5794973874098034:.2f\n",
      "Epoch 7140 | Train Loss: 0.944 | Train F1: 0.5795595919382931:.2f\n",
      "Epoch 7150 | Train Loss: 0.944 | Train F1: 0.5796217964667828:.2f\n",
      "Epoch 7160 | Train Loss: 0.944 | Train F1: 0.5795595919382931:.2f\n",
      "Epoch 7170 | Train Loss: 0.944 | Train F1: 0.5795595919382931:.2f\n",
      "Epoch 7180 | Train Loss: 0.944 | Train F1: 0.5795595919382931:.2f\n",
      "Epoch 7190 | Train Loss: 0.944 | Train F1: 0.5795595919382931:.2f\n",
      "Epoch 7200 | Train Loss: 0.944 | Train F1: 0.5795595919382931:.2f\n",
      "Epoch 7210 | Train Loss: 0.944 | Train F1: 0.5795595919382931:.2f\n",
      "Epoch 7220 | Train Loss: 0.944 | Train F1: 0.5795595919382931:.2f\n",
      "Epoch 7230 | Train Loss: 0.944 | Train F1: 0.5795595919382931:.2f\n",
      "Epoch 7240 | Train Loss: 0.944 | Train F1: 0.5794973874098034:.2f\n",
      "Epoch 7250 | Train Loss: 0.944 | Train F1: 0.5794973874098034:.2f\n",
      "Epoch 7260 | Train Loss: 0.944 | Train F1: 0.5794973874098034:.2f\n",
      "Epoch 7270 | Train Loss: 0.944 | Train F1: 0.5794351828813138:.2f\n",
      "Epoch 7280 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7290 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7300 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7310 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7320 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7330 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7340 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7350 | Train Loss: 0.944 | Train F1: 0.5793729783528241:.2f\n",
      "Epoch 7360 | Train Loss: 0.944 | Train F1: 0.5793729783528241:.2f\n",
      "Epoch 7370 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7380 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7390 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7400 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7410 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7420 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7430 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7440 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7450 | Train Loss: 0.944 | Train F1: 0.5793729783528241:.2f\n",
      "Epoch 7460 | Train Loss: 0.944 | Train F1: 0.5793729783528241:.2f\n",
      "Epoch 7470 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7480 | Train Loss: 0.944 | Train F1: 0.5793107738243344:.2f\n",
      "Epoch 7490 | Train Loss: 0.944 | Train F1: 0.5792485692958448:.2f\n",
      "Epoch 7500 | Train Loss: 0.944 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 7510 | Train Loss: 0.944 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 7520 | Train Loss: 0.944 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 7530 | Train Loss: 0.944 | Train F1: 0.5791863647673551:.2f\n",
      "Epoch 7540 | Train Loss: 0.944 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 7550 | Train Loss: 0.944 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 7560 | Train Loss: 0.944 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 7570 | Train Loss: 0.944 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 7580 | Train Loss: 0.944 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 7590 | Train Loss: 0.944 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 7600 | Train Loss: 0.944 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 7610 | Train Loss: 0.944 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 7620 | Train Loss: 0.944 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 7630 | Train Loss: 0.944 | Train F1: 0.5791241602388654:.2f\n",
      "Epoch 7640 | Train Loss: 0.944 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 7650 | Train Loss: 0.944 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 7660 | Train Loss: 0.944 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 7670 | Train Loss: 0.944 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 7680 | Train Loss: 0.944 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 7690 | Train Loss: 0.944 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 7700 | Train Loss: 0.944 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 7710 | Train Loss: 0.944 | Train F1: 0.5790619557103757:.2f\n",
      "Epoch 7720 | Train Loss: 0.944 | Train F1: 0.5789997511818861:.2f\n",
      "Epoch 7730 | Train Loss: 0.944 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 7740 | Train Loss: 0.944 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 7750 | Train Loss: 0.944 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 7760 | Train Loss: 0.944 | Train F1: 0.5789375466533964:.2f\n",
      "Epoch 7770 | Train Loss: 0.944 | Train F1: 0.5788131375964171:.2f\n",
      "Epoch 7780 | Train Loss: 0.944 | Train F1: 0.5786887285394376:.2f\n",
      "Epoch 7790 | Train Loss: 0.944 | Train F1: 0.578626524010948:.2f\n",
      "Epoch 7800 | Train Loss: 0.944 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 7810 | Train Loss: 0.944 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 7820 | Train Loss: 0.944 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 7830 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 7840 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 7850 | Train Loss: 0.944 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 7860 | Train Loss: 0.944 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 7870 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 7880 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 7890 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 7900 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 7910 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 7920 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 7930 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 7940 | Train Loss: 0.944 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 7950 | Train Loss: 0.944 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 7960 | Train Loss: 0.944 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 7970 | Train Loss: 0.944 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 7980 | Train Loss: 0.944 | Train F1: 0.5785643194824583:.2f\n",
      "Epoch 7990 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8000 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8010 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8020 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8030 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8040 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8050 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 8060 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 8070 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 8080 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 8090 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 8100 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8110 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8120 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8130 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8140 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8150 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8160 | Train Loss: 0.944 | Train F1: 0.5783777058969893:.2f\n",
      "Epoch 8170 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8180 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8190 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8200 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8210 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8220 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8230 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8240 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8250 | Train Loss: 0.944 | Train F1: 0.5784399104254789:.2f\n",
      "Epoch 8260 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 8270 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 8280 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 8290 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 8300 | Train Loss: 0.944 | Train F1: 0.5785021149539686:.2f\n",
      "Epoch 8310 | Train Loss: 0.944 | Train F1: 0.5787509330679274:.2f\n",
      "Epoch 8320 | Train Loss: 0.944 | Train F1: 0.5788753421249067:.2f\n",
      "Epoch 8330 | Train Loss: 0.944 | Train F1: 0.5806170689226176:.2f\n",
      "Epoch 8340 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8350 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8360 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8370 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8380 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8390 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8400 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8410 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8420 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8430 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8440 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8450 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8460 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8470 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8480 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8490 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8500 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8510 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8520 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8530 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8540 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8550 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8560 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8570 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8580 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8590 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8600 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8610 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8620 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8630 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8640 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8650 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8660 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8670 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8680 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8690 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8700 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8710 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8720 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8730 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8740 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8750 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8760 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8770 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8780 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8790 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8800 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8810 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8820 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8830 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8840 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8850 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8860 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8870 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8880 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8890 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8900 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8910 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8920 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8930 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8940 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8950 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8960 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8970 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8980 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 8990 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9000 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9010 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9020 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9030 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9040 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9050 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9060 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9070 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9080 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9090 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9100 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9110 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9120 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9130 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9140 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9150 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9160 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9170 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9180 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9190 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9200 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9210 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9220 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9230 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9240 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9250 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9260 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9270 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9280 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9290 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9300 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9310 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9320 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9330 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9340 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9350 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9360 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9370 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9380 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9390 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9400 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9410 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9420 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9430 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9440 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9450 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9460 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9470 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9480 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9490 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9500 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9510 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9520 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9530 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9540 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9550 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9560 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9570 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9580 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9590 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9600 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9610 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9620 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9630 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9640 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9650 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9660 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9670 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9680 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9690 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9700 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9710 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9720 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9730 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9740 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9750 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9760 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9770 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9780 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9790 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9800 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9810 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9820 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9830 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9840 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9850 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9860 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9870 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9880 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9890 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9900 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9910 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9920 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9930 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9940 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9950 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9960 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9970 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9980 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 9990 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "Epoch 10000 | Train Loss: 0.944 | Train F1: 0.580741477979597:.2f\n",
      "\n",
      "GAT Dataset Test F1 score: 0.34494\n",
      "\n",
      "GAT Dataset Test AUC score: 0.53643\n"
     ]
    }
   ],
   "source": [
    "best_config['epochs'] = 10000\n",
    "\n",
    "model = GAT(best_config, data.num_features, 3)\n",
    "model.fit(data, True)\n",
    "\n",
    "data.to(model.device)\n",
    "\n",
    "model.eval()\n",
    "_, out = model(data.x, data.edge_index)\n",
    "\n",
    "print(f'\\nGAT Dataset Test F1 score: {test_f1(model, data, data.test_mask):.5f}')\n",
    "print(f'\\nGAT Dataset Test AUC score: {test_auc(model, data, data.test_mask):.5f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
