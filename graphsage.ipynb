{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook Content\n",
    "In this notebook the 3 datasets are being setup and tested using the GraphSAGE model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Import packages\n",
    "We will use _PyTorch_ as the main Neural Networks package, and we will add _PyTorch Geometric_ as a utility package that implements Graph functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from graphsage import *\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Read input data\n",
    "Read the node features and edge list from the respective files.\n",
    "Construct a Data object from the features and edge list and split the data into train/val/test sets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Nodes: 190, Val Nodes: 950, Test Nodes: 1901\n",
      "\n",
      "Train Set Class Distribution: Left: 63, Middle: 63, Right: 64\n",
      "Val Set Class Distribution: Left: 317, Middle: 316, Right: 317\n",
      "Test Set Class Distribution: Left: 635, Middle: 633, Right: 633\n",
      "\n",
      "Nodes: 23607, Edges: 253528, Node Features: 17\n"
     ]
    }
   ],
   "source": [
    "node_features = pd.read_pickle('data/dataset3.pkl')\n",
    "edge_list = pd.read_pickle('data/graph_weighted_edgeList_61.pkl')\n",
    "data = graph_to_data_object(node_features, edge_list, 0.01, 0.05, 0.1)\n",
    "print(f\"\\nNodes: {data.x.shape[0]}, Edges: {int(data.edge_index.shape[1] / 2)}, Node Features: {data.num_features}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Grid search GraphSAGE Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {'architecture': 'two-layer', 'batch': 16, 'lr': 0.001, 'l2': 0.005, 'aggr': 'mean', 'proj': False, 'epochs': 200, 'dim_h1': 8, 'dim_h2': 0}, Run time: 38 seconds\n",
      "Config: {'architecture': 'two-layer', 'batch': 16, 'lr': 0.001, 'l2': 0.0005, 'aggr': 'mean', 'proj': False, 'epochs': 200, 'dim_h1': 8, 'dim_h2': 0}, Run time: 38 seconds\n",
      "Config: {'architecture': 'two-layer', 'batch': 16, 'lr': 0.0001, 'l2': 0.005, 'aggr': 'mean', 'proj': False, 'epochs': 200, 'dim_h1': 8, 'dim_h2': 0}, Run time: 38 seconds\n",
      "Config: {'architecture': 'two-layer', 'batch': 16, 'lr': 0.0001, 'l2': 0.0005, 'aggr': 'mean', 'proj': False, 'epochs': 200, 'dim_h1': 8, 'dim_h2': 0}, Run time: 38 seconds\n",
      "Config: {'architecture': 'two-layer', 'batch': 16, 'lr': 0.001, 'l2': 0.005, 'aggr': 'max', 'proj': True, 'epochs': 200, 'dim_h1': 8, 'dim_h2': 0}, Run time: 43 seconds\n",
      "Config: {'architecture': 'two-layer', 'batch': 16, 'lr': 0.001, 'l2': 0.0005, 'aggr': 'max', 'proj': True, 'epochs': 200, 'dim_h1': 8, 'dim_h2': 0}, Run time: 43 seconds\n",
      "Config: {'architecture': 'two-layer', 'batch': 16, 'lr': 0.0001, 'l2': 0.005, 'aggr': 'max', 'proj': True, 'epochs': 200, 'dim_h1': 8, 'dim_h2': 0}, Run time: 42 seconds\n",
      "Config: {'architecture': 'two-layer', 'batch': 16, 'lr': 0.0001, 'l2': 0.0005, 'aggr': 'max', 'proj': True, 'epochs': 200, 'dim_h1': 8, 'dim_h2': 0}, Run time: 42 seconds\n",
      "Config: {'architecture': 'three-layer', 'batch': 16, 'lr': 0.001, 'l2': 0.005, 'aggr': 'mean', 'proj': False, 'epochs': 200, 'dim_h1': 64, 'dim_h2': 8}, Run time: 44 seconds\n",
      "Config: {'architecture': 'three-layer', 'batch': 16, 'lr': 0.001, 'l2': 0.0005, 'aggr': 'mean', 'proj': False, 'epochs': 200, 'dim_h1': 64, 'dim_h2': 8}, Run time: 44 seconds\n",
      "Config: {'architecture': 'three-layer', 'batch': 16, 'lr': 0.0001, 'l2': 0.005, 'aggr': 'mean', 'proj': False, 'epochs': 200, 'dim_h1': 64, 'dim_h2': 8}, Run time: 44 seconds\n",
      "Config: {'architecture': 'three-layer', 'batch': 16, 'lr': 0.0001, 'l2': 0.0005, 'aggr': 'mean', 'proj': False, 'epochs': 200, 'dim_h1': 64, 'dim_h2': 8}, Run time: 43 seconds\n",
      "Config: {'architecture': 'three-layer', 'batch': 16, 'lr': 0.001, 'l2': 0.005, 'aggr': 'max', 'proj': True, 'epochs': 200, 'dim_h1': 64, 'dim_h2': 8}, Run time: 47 seconds\n",
      "Config: {'architecture': 'three-layer', 'batch': 16, 'lr': 0.001, 'l2': 0.0005, 'aggr': 'max', 'proj': True, 'epochs': 200, 'dim_h1': 64, 'dim_h2': 8}, Run time: 48 seconds\n",
      "Config: {'architecture': 'three-layer', 'batch': 16, 'lr': 0.0001, 'l2': 0.005, 'aggr': 'max', 'proj': True, 'epochs': 200, 'dim_h1': 64, 'dim_h2': 8}, Run time: 48 seconds\n",
      "Config: {'architecture': 'three-layer', 'batch': 16, 'lr': 0.0001, 'l2': 0.0005, 'aggr': 'max', 'proj': True, 'epochs': 200, 'dim_h1': 64, 'dim_h2': 8}, Run time: 48 seconds\n",
      "\n",
      "Run time: 688.3488924503326 seconds\n",
      "Best model config: {'architecture': 'three-layer', 'batch': 16, 'lr': 0.001, 'l2': 0.0005, 'aggr': 'mean', 'proj': False, 'epochs': 200, 'dim_h1': 64, 'dim_h2': 8}\n",
      "\n",
      "GraphSAGE Dataset Test F1 score: 0.34\n",
      "\n",
      "GraphSAGE Dataset Test AUC score: 0.50\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = [\n",
    "  {'architecture': ['two-layer'], 'lr': [1e-3, 1e-4], 'l2': [5e-3, 5e-4], 'batch': [16], 'aggr': ['mean'], 'proj': [False], 'epochs': [200], 'dim_h1': [8], 'dim_h2': [0]},\n",
    "  {'architecture': ['two-layer'], 'lr': [1e-3, 1e-4], 'l2': [5e-3, 5e-4], 'batch': [16], 'aggr': ['max'], 'proj': [True], 'epochs': [200], 'dim_h1': [8], 'dim_h2': [0]},\n",
    "  {'architecture': ['three-layer'], 'lr': [1e-3, 1e-4], 'l2': [5e-3, 5e-4], 'batch': [16], 'aggr': ['mean'], 'proj': [False], 'epochs': [200], 'dim_h1': [64], 'dim_h2': [8]},\n",
    "  {'architecture': ['three-layer'], 'lr': [1e-3, 1e-4], 'l2': [5e-3, 5e-4], 'batch': [16], 'aggr': ['max'], 'proj': [True], 'epochs': [200], 'dim_h1': [64], 'dim_h2': [8]},\n",
    "]\n",
    "\n",
    "best_model, best_config = grid_search_cv(data, 3, param_grid)\n",
    "print(f\"\\nRun time: {time.time() - start_time} seconds\")\n",
    "print(f\"Best model config: {best_config}\")\n",
    "\n",
    "print(f'\\nGraphSAGE Dataset Test F1 score: {test_f1(best_model, data, data.test_mask):.2f}')\n",
    "print(f'\\nGraphSAGE Dataset Test AUC score: {test_auc(best_model, data, data.test_mask):.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3. Train and test the best GraphSAGE Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  10 | Train Loss: 0.091 | Train F1: 0.02\n",
      "Epoch  20 | Train Loss: 0.090 | Train F1: 0.03\n",
      "Epoch  30 | Train Loss: 0.090 | Train F1: 0.03\n",
      "Epoch  40 | Train Loss: 0.091 | Train F1: 0.03\n",
      "Epoch  50 | Train Loss: 0.093 | Train F1: 0.03\n",
      "Epoch  60 | Train Loss: 0.092 | Train F1: 0.03\n",
      "Epoch  70 | Train Loss: 0.094 | Train F1: 0.02\n",
      "Epoch  80 | Train Loss: 0.092 | Train F1: 0.03\n",
      "Epoch  90 | Train Loss: 0.088 | Train F1: 0.03\n",
      "Epoch 100 | Train Loss: 0.092 | Train F1: 0.03\n",
      "Epoch 110 | Train Loss: 0.092 | Train F1: 0.02\n",
      "Epoch 120 | Train Loss: 0.092 | Train F1: 0.02\n",
      "Epoch 130 | Train Loss: 0.089 | Train F1: 0.03\n",
      "Epoch 140 | Train Loss: 0.089 | Train F1: 0.03\n",
      "Epoch 150 | Train Loss: 0.088 | Train F1: 0.04\n",
      "Epoch 160 | Train Loss: 0.089 | Train F1: 0.03\n",
      "Epoch 170 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 180 | Train Loss: 0.088 | Train F1: 0.04\n",
      "Epoch 190 | Train Loss: 0.090 | Train F1: 0.03\n",
      "Epoch 200 | Train Loss: 0.087 | Train F1: 0.04\n",
      "Epoch 210 | Train Loss: 0.088 | Train F1: 0.03\n",
      "Epoch 220 | Train Loss: 0.088 | Train F1: 0.03\n",
      "Epoch 230 | Train Loss: 0.087 | Train F1: 0.03\n",
      "Epoch 240 | Train Loss: 0.089 | Train F1: 0.03\n",
      "Epoch 250 | Train Loss: 0.086 | Train F1: 0.04\n",
      "Epoch 260 | Train Loss: 0.086 | Train F1: 0.04\n",
      "Epoch 270 | Train Loss: 0.087 | Train F1: 0.03\n",
      "Epoch 280 | Train Loss: 0.086 | Train F1: 0.04\n",
      "Epoch 290 | Train Loss: 0.087 | Train F1: 0.03\n",
      "Epoch 300 | Train Loss: 0.086 | Train F1: 0.04\n",
      "Epoch 310 | Train Loss: 0.087 | Train F1: 0.03\n",
      "Epoch 320 | Train Loss: 0.083 | Train F1: 0.04\n",
      "Epoch 330 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 340 | Train Loss: 0.088 | Train F1: 0.03\n",
      "Epoch 350 | Train Loss: 0.087 | Train F1: 0.03\n",
      "Epoch 360 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 370 | Train Loss: 0.089 | Train F1: 0.03\n",
      "Epoch 380 | Train Loss: 0.087 | Train F1: 0.03\n",
      "Epoch 390 | Train Loss: 0.088 | Train F1: 0.04\n",
      "Epoch 400 | Train Loss: 0.087 | Train F1: 0.04\n",
      "Epoch 410 | Train Loss: 0.086 | Train F1: 0.03\n",
      "Epoch 420 | Train Loss: 0.086 | Train F1: 0.04\n",
      "Epoch 430 | Train Loss: 0.087 | Train F1: 0.04\n",
      "Epoch 440 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 450 | Train Loss: 0.088 | Train F1: 0.03\n",
      "Epoch 460 | Train Loss: 0.085 | Train F1: 0.03\n",
      "Epoch 470 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 480 | Train Loss: 0.086 | Train F1: 0.04\n",
      "Epoch 490 | Train Loss: 0.084 | Train F1: 0.03\n",
      "Epoch 500 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 510 | Train Loss: 0.087 | Train F1: 0.03\n",
      "Epoch 520 | Train Loss: 0.089 | Train F1: 0.04\n",
      "Epoch 530 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 540 | Train Loss: 0.088 | Train F1: 0.04\n",
      "Epoch 550 | Train Loss: 0.086 | Train F1: 0.03\n",
      "Epoch 560 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 570 | Train Loss: 0.086 | Train F1: 0.04\n",
      "Epoch 580 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 590 | Train Loss: 0.086 | Train F1: 0.03\n",
      "Epoch 600 | Train Loss: 0.087 | Train F1: 0.04\n",
      "Epoch 610 | Train Loss: 0.084 | Train F1: 0.06\n",
      "Epoch 620 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 630 | Train Loss: 0.084 | Train F1: 0.05\n",
      "Epoch 640 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 650 | Train Loss: 0.083 | Train F1: 0.04\n",
      "Epoch 660 | Train Loss: 0.089 | Train F1: 0.04\n",
      "Epoch 670 | Train Loss: 0.083 | Train F1: 0.04\n",
      "Epoch 680 | Train Loss: 0.082 | Train F1: 0.05\n",
      "Epoch 690 | Train Loss: 0.083 | Train F1: 0.04\n",
      "Epoch 700 | Train Loss: 0.085 | Train F1: 0.03\n",
      "Epoch 710 | Train Loss: 0.084 | Train F1: 0.05\n",
      "Epoch 720 | Train Loss: 0.090 | Train F1: 0.03\n",
      "Epoch 730 | Train Loss: 0.086 | Train F1: 0.05\n",
      "Epoch 740 | Train Loss: 0.089 | Train F1: 0.04\n",
      "Epoch 750 | Train Loss: 0.085 | Train F1: 0.05\n",
      "Epoch 760 | Train Loss: 0.082 | Train F1: 0.06\n",
      "Epoch 770 | Train Loss: 0.087 | Train F1: 0.04\n",
      "Epoch 780 | Train Loss: 0.082 | Train F1: 0.05\n",
      "Epoch 790 | Train Loss: 0.090 | Train F1: 0.03\n",
      "Epoch 800 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 810 | Train Loss: 0.088 | Train F1: 0.04\n",
      "Epoch 820 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 830 | Train Loss: 0.087 | Train F1: 0.05\n",
      "Epoch 840 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 850 | Train Loss: 0.083 | Train F1: 0.06\n",
      "Epoch 860 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 870 | Train Loss: 0.086 | Train F1: 0.05\n",
      "Epoch 880 | Train Loss: 0.084 | Train F1: 0.06\n",
      "Epoch 890 | Train Loss: 0.085 | Train F1: 0.06\n",
      "Epoch 900 | Train Loss: 0.083 | Train F1: 0.04\n",
      "Epoch 910 | Train Loss: 0.085 | Train F1: 0.05\n",
      "Epoch 920 | Train Loss: 0.088 | Train F1: 0.03\n",
      "Epoch 930 | Train Loss: 0.087 | Train F1: 0.03\n",
      "Epoch 940 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 950 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 960 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 970 | Train Loss: 0.084 | Train F1: 0.05\n",
      "Epoch 980 | Train Loss: 0.086 | Train F1: 0.04\n",
      "Epoch 990 | Train Loss: 0.085 | Train F1: 0.05\n",
      "Epoch 1000 | Train Loss: 0.082 | Train F1: 0.05\n",
      "Epoch 1010 | Train Loss: 0.082 | Train F1: 0.05\n",
      "Epoch 1020 | Train Loss: 0.081 | Train F1: 0.05\n",
      "Epoch 1030 | Train Loss: 0.084 | Train F1: 0.05\n",
      "Epoch 1040 | Train Loss: 0.084 | Train F1: 0.05\n",
      "Epoch 1050 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 1060 | Train Loss: 0.088 | Train F1: 0.03\n",
      "Epoch 1070 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 1080 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 1090 | Train Loss: 0.081 | Train F1: 0.05\n",
      "Epoch 1100 | Train Loss: 0.081 | Train F1: 0.05\n",
      "Epoch 1110 | Train Loss: 0.081 | Train F1: 0.06\n",
      "Epoch 1120 | Train Loss: 0.080 | Train F1: 0.06\n",
      "Epoch 1130 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 1140 | Train Loss: 0.080 | Train F1: 0.05\n",
      "Epoch 1150 | Train Loss: 0.081 | Train F1: 0.05\n",
      "Epoch 1160 | Train Loss: 0.083 | Train F1: 0.04\n",
      "Epoch 1170 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 1180 | Train Loss: 0.080 | Train F1: 0.05\n",
      "Epoch 1190 | Train Loss: 0.083 | Train F1: 0.06\n",
      "Epoch 1200 | Train Loss: 0.087 | Train F1: 0.04\n",
      "Epoch 1210 | Train Loss: 0.080 | Train F1: 0.05\n",
      "Epoch 1220 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 1230 | Train Loss: 0.083 | Train F1: 0.04\n",
      "Epoch 1240 | Train Loss: 0.080 | Train F1: 0.06\n",
      "Epoch 1250 | Train Loss: 0.083 | Train F1: 0.04\n",
      "Epoch 1260 | Train Loss: 0.082 | Train F1: 0.05\n",
      "Epoch 1270 | Train Loss: 0.082 | Train F1: 0.05\n",
      "Epoch 1280 | Train Loss: 0.081 | Train F1: 0.06\n",
      "Epoch 1290 | Train Loss: 0.081 | Train F1: 0.05\n",
      "Epoch 1300 | Train Loss: 0.080 | Train F1: 0.05\n",
      "Epoch 1310 | Train Loss: 0.085 | Train F1: 0.06\n",
      "Epoch 1320 | Train Loss: 0.080 | Train F1: 0.06\n",
      "Epoch 1330 | Train Loss: 0.086 | Train F1: 0.04\n",
      "Epoch 1340 | Train Loss: 0.086 | Train F1: 0.03\n",
      "Epoch 1350 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 1360 | Train Loss: 0.081 | Train F1: 0.04\n",
      "Epoch 1370 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 1380 | Train Loss: 0.081 | Train F1: 0.05\n",
      "Epoch 1390 | Train Loss: 0.081 | Train F1: 0.06\n",
      "Epoch 1400 | Train Loss: 0.084 | Train F1: 0.05\n",
      "Epoch 1410 | Train Loss: 0.081 | Train F1: 0.05\n",
      "Epoch 1420 | Train Loss: 0.081 | Train F1: 0.04\n",
      "Epoch 1430 | Train Loss: 0.086 | Train F1: 0.04\n",
      "Epoch 1440 | Train Loss: 0.086 | Train F1: 0.03\n",
      "Epoch 1450 | Train Loss: 0.086 | Train F1: 0.04\n",
      "Epoch 1460 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 1470 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 1480 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 1490 | Train Loss: 0.077 | Train F1: 0.06\n",
      "Epoch 1500 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 1510 | Train Loss: 0.080 | Train F1: 0.05\n",
      "Epoch 1520 | Train Loss: 0.084 | Train F1: 0.05\n",
      "Epoch 1530 | Train Loss: 0.081 | Train F1: 0.05\n",
      "Epoch 1540 | Train Loss: 0.085 | Train F1: 0.05\n",
      "Epoch 1550 | Train Loss: 0.083 | Train F1: 0.04\n",
      "Epoch 1560 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 1570 | Train Loss: 0.079 | Train F1: 0.06\n",
      "Epoch 1580 | Train Loss: 0.077 | Train F1: 0.06\n",
      "Epoch 1590 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 1600 | Train Loss: 0.080 | Train F1: 0.05\n",
      "Epoch 1610 | Train Loss: 0.081 | Train F1: 0.05\n",
      "Epoch 1620 | Train Loss: 0.083 | Train F1: 0.04\n",
      "Epoch 1630 | Train Loss: 0.085 | Train F1: 0.05\n",
      "Epoch 1640 | Train Loss: 0.082 | Train F1: 0.05\n",
      "Epoch 1650 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 1660 | Train Loss: 0.081 | Train F1: 0.04\n",
      "Epoch 1670 | Train Loss: 0.078 | Train F1: 0.05\n",
      "Epoch 1680 | Train Loss: 0.078 | Train F1: 0.05\n",
      "Epoch 1690 | Train Loss: 0.083 | Train F1: 0.04\n",
      "Epoch 1700 | Train Loss: 0.081 | Train F1: 0.04\n",
      "Epoch 1710 | Train Loss: 0.079 | Train F1: 0.05\n",
      "Epoch 1720 | Train Loss: 0.080 | Train F1: 0.05\n",
      "Epoch 1730 | Train Loss: 0.080 | Train F1: 0.05\n",
      "Epoch 1740 | Train Loss: 0.079 | Train F1: 0.06\n",
      "Epoch 1750 | Train Loss: 0.080 | Train F1: 0.06\n",
      "Epoch 1760 | Train Loss: 0.081 | Train F1: 0.04\n",
      "Epoch 1770 | Train Loss: 0.080 | Train F1: 0.05\n",
      "Epoch 1780 | Train Loss: 0.078 | Train F1: 0.04\n",
      "Epoch 1790 | Train Loss: 0.082 | Train F1: 0.04\n",
      "Epoch 1800 | Train Loss: 0.076 | Train F1: 0.06\n",
      "Epoch 1810 | Train Loss: 0.081 | Train F1: 0.05\n",
      "Epoch 1820 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 1830 | Train Loss: 0.079 | Train F1: 0.05\n",
      "Epoch 1840 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 1850 | Train Loss: 0.082 | Train F1: 0.05\n",
      "Epoch 1860 | Train Loss: 0.084 | Train F1: 0.04\n",
      "Epoch 1870 | Train Loss: 0.082 | Train F1: 0.04\n",
      "Epoch 1880 | Train Loss: 0.080 | Train F1: 0.05\n",
      "Epoch 1890 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 1900 | Train Loss: 0.079 | Train F1: 0.05\n",
      "Epoch 1910 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 1920 | Train Loss: 0.085 | Train F1: 0.04\n",
      "Epoch 1930 | Train Loss: 0.083 | Train F1: 0.05\n",
      "Epoch 1940 | Train Loss: 0.081 | Train F1: 0.05\n",
      "Epoch 1950 | Train Loss: 0.079 | Train F1: 0.05\n",
      "Epoch 1960 | Train Loss: 0.082 | Train F1: 0.05\n",
      "Epoch 1970 | Train Loss: 0.079 | Train F1: 0.06\n",
      "Epoch 1980 | Train Loss: 0.079 | Train F1: 0.05\n",
      "Epoch 1990 | Train Loss: 0.076 | Train F1: 0.06\n",
      "Epoch 2000 | Train Loss: 0.077 | Train F1: 0.05\n",
      "\n",
      "GraphSAGE Dataset Test F1 score: 0.34087\n",
      "\n",
      "GraphSAGE Dataset Test AUC score: 0.52611\n"
     ]
    }
   ],
   "source": [
    "best_config['epochs'] = 2000\n",
    "\n",
    "model = GraphSAGE(best_config, data.num_features, 3)\n",
    "model.fit(data, True)\n",
    "\n",
    "data.to(model.device)\n",
    "\n",
    "model.eval()\n",
    "_, out = model(data.x, data.edge_index)\n",
    "\n",
    "print(f'\\nGraphSAGE Dataset Test F1 score: {test_f1(model, data, data.test_mask):.5f}')\n",
    "print(f'\\nGraphSAGE Dataset Test AUC score: {test_auc(model, data, data.test_mask):.5f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
